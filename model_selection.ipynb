{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92303e04-bb5a-48d7-bb2d-c619a77e407c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: torchsde 0.2.5 has a non-standard dependency specifier numpy>=1.19.*; python_version >= \"3.7\". pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of torchsde or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "124fc469-ba30-46a4-a471-26975e605506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51577ba9-7ac2-490c-bb78-488cebe75ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['প্রধানমন্ত্রী শেখ হাসিনা বলেছেন, ‘আমাকে বেশি কথা বললে সব বন্ধ করে দিয়ে বসে থাকব। ইলেকশনের পরে, যদি আসতে পারি, আবার করব। তারপর দেখি কে সাহস পায় নিতে...ক্ষমতা।',\n",
    "             'প্রতারণা ও জালিয়াতির মামলায় কুমিল্লা দক্ষিণ জেলা আওয়ামী লীগের সাংস্কৃতিক সম্পাদক নিশাত আহমেদ খানকে গ্রেপ্তার করেছে পুলিশ। বুধবার রাজধানীর বনশ্রী এলাকার একটি বাসা থেকে তাঁকে গ্রেপ্তার করা হয়।',\n",
    "             'দেশে বৈদেশিক মুদ্রার রিজার্ভ কমছেই। গত সেপ্টেম্বর মাসের প্রথম ২৬ দিনে বৈদেশিক মুদ্রার রিজার্ভ কমেছিল ১৯১ কোটি ৪৮ লাখ মার্কিন ডলার']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f8d61a6-c3b0-4c01-9a65-023ad5f82c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['প', '##র', '##ধ', '##া', '##ন', '##ম', '##ন', '##ত', '##র', '##ী', 'শ', '##ে', '##খ', 'হ', '##া', '##স', '##ি', '##ন', '##া', 'ব', '##ল', '##ে', '##ছ', '##ে', '##ন', ',', '‘', 'আ', '##ম', '##া', '##ক', '##ে', 'ব', '##ে', '##শ', '##ি', 'ক', '##থ', '##া', 'ব', '##ল', '##ল', '##ে', 'স', '##ব', 'ব', '##ন', '##ধ', 'ক', '##র', '##ে', 'দ', '##ি', '##য', '##ে', 'ব', '##স', '##ে', 'থ', '##া', '##ক', '##ব', '।', 'ই', '##ল', '##ে', '##ক', '##শ', '##ন', '##ে', '##র', 'প', '##র', '##ে', ',', 'য', '##দ', '##ি', 'আ', '##স', '##ত', '##ে', 'প', '##া', '##র', '##ি', ',', 'আ', '##ব', '##া', '##র', 'ক', '##র', '##ব', '।', 'ত', '##া', '##র', '##প', '##র', 'দ', '##ে', '##খ', '##ি', 'ক', '##ে', 'স', '##া', '##হ', '##স', 'প', '##া', '##য', 'ন', '##ি', '##ত', '##ে', '.', '.', '.', 'ক', '##ষ', '##ম', '##ত', '##া', '।']\n",
      "['প', '##র', '##ত', '##া', '##র', '##ণ', '##া', 'ও', 'জ', '##া', '##ল', '##ি', '##য', '##া', '##ত', '##ি', '##র', 'ম', '##া', '##ম', '##ল', '##া', '##য', 'ক', '##ম', '##ি', '##ল', '##ল', '##া', 'দ', '##ক', '##ষ', '##ি', '##ণ', 'জ', '##ে', '##ল', '##া', 'আ', '##ও', '##য', '##া', '##ম', '##ী', 'ল', '##ী', '##গ', '##ে', '##র', 'স', '##া', '##ং', '##স', '##ক', '##ত', '##ি', '##ক', 'স', '##ম', '##প', '##া', '##দ', '##ক', 'ন', '##ি', '##শ', '##া', '##ত', 'আ', '##হ', '##ম', '##ে', '##দ', 'খ', '##া', '##ন', '##ক', '##ে', 'গ', '##র', '##ে', '##প', '##ত', '##া', '##র', 'ক', '##র', '##ে', '##ছ', '##ে', 'প', '##ল', '##ি', '##শ', '।', 'ব', '##ধ', '##ব', '##া', '##র', 'র', '##া', '##জ', '##ধ', '##া', '##ন', '##ী', '##র', 'ব', '##ন', '##শ', '##র', '##ী', 'এ', '##ল', '##া', '##ক', '##া', '##র', 'এ', '##ক', '##ট', '##ি', 'ব', '##া', '##স', '##া', 'থ', '##ে', '##ক', '##ে', 'ত', '##া', '##ক', '##ে', 'গ', '##র', '##ে', '##প', '##ত', '##া', '##র', 'ক', '##র', '##া', 'হ', '##য', '।']\n",
      "['দ', '##ে', '##শ', '##ে', '[UNK]', 'ম', '##দ', '##র', '##া', '##র', 'র', '##ি', '##জ', '##া', '##র', '##ভ', 'ক', '##ম', '##ছ', '##ে', '##ই', '।', 'গ', '##ত', 'স', '##ে', '##প', '##ট', '##ে', '##ম', '##ব', '##র', 'ম', '##া', '##স', '##ে', '##র', 'প', '##র', '##থ', '##ম', '[UNK]', 'দ', '##ি', '##ন', '##ে', '[UNK]', 'ম', '##দ', '##র', '##া', '##র', 'র', '##ি', '##জ', '##া', '##র', '##ভ', 'ক', '##ম', '##ে', '##ছ', '##ি', '##ল', '[UNK]', 'ক', '##ে', '##া', '##ট', '##ি', '[UNK]', 'ল', '##া', '##খ', 'ম', '##া', '##র', '##ক', '##ি', '##ন', 'ড', '##ল', '##া', '##র']\n"
     ]
    }
   ],
   "source": [
    "for text in sentences:\n",
    "    print(bert_tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c694f2c3-933c-40d2-9b08-80bdcf0cc1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers -q\n",
    "# !pip install torchsde==0.2.6 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f588869-e17a-4160-938b-6e17bd0b8bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: sentencepiece 0.1.97\n",
      "Uninstalling sentencepiece-0.1.97:\n",
      "  Successfully uninstalled sentencepiece-0.1.97\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall sentencepiece -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "416f5ee1-0827-4b24-a88e-a15dc9286cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentencepiece -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cd85911-ee43-4468-ad34-8e6a2737ae9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9b75c99e1f490daf646ad1211f9175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9bcbfc760494e03ada9376e4030309f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee793a3bceb44e198366ab4816be32e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "\n",
    "# xlmr_tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c601fff-89d8-4656-9b8c-e8d3e0c571d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁প্রধানমন্ত্রী', '▁শেখ', '▁হাসিনা', '▁বলেছেন', ',', '▁‘', 'আ', 'মা', 'কে', '▁বেশি', '▁কথা', '▁বল', 'লে', '▁সব', '▁বন্ধ', '▁করে', '▁দিয়ে', '▁বসে', '▁থাক', 'ব', '।', '▁', 'ইল', 'েক', 'শন', 'ের', '▁পরে', ',', '▁যদি', '▁আস', 'তে', '▁পারি', ',', '▁আবার', '▁করব', '।', '▁তারপর', '▁দেখ', 'ি', '▁কে', '▁সা', 'হ', 'স', '▁পায়', '▁নিতে', '...', 'ক্ষ', 'ম', 'তা', '।']\n",
      "['▁প্র', 'তার', 'ণা', '▁ও', '▁জা', 'লিয়া', 'তি', 'র', '▁মামলায়', '▁কুমিল্লা', '▁দক্ষিণ', '▁জেলা', '▁আওয়ামী', '▁লীগের', '▁সা', 'ং', 'স্', 'কৃত', 'িক', '▁সম্পাদক', '▁নি', 'শা', 'ত', '▁আহমেদ', '▁খান', 'কে', '▁গ্রেপ্তার', '▁করেছে', '▁পুলিশ', '।', '▁বুধবার', '▁রাজধানীর', '▁', 'বন', 'শ্', 'রী', '▁এলাকা', 'র', '▁একটি', '▁বা', 'সা', '▁থেকে', '▁তা', 'ঁ', 'কে', '▁গ্রেপ্তার', '▁করা', '▁হয়', '।']\n",
      "['▁দেশে', '▁বৈ', 'দেশ', 'িক', '▁মু', 'দ্র', 'ার', '▁রি', 'জা', 'র্', 'ভ', '▁কম', 'ছে', 'ই', '।', '▁গত', '▁সেপ্টেম্বর', '▁মাসের', '▁প্রথম', '▁', '২৬', '▁দিনে', '▁বৈ', 'দেশ', 'িক', '▁মু', 'দ্র', 'ার', '▁রি', 'জা', 'র্', 'ভ', '▁কম', 'ে', 'ছিল', '▁১৯', '১', '▁কোটি', '▁', '৪৮', '▁লাখ', '▁মার্কিন', '▁ডলার']\n"
     ]
    }
   ],
   "source": [
    "for text in sentences:\n",
    "    print(xlmr_tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e10b6dc-6b38-44bd-abb2-35080eb75b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9810c8768b48269a1d91ee0a457a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distilbert_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2c16cae-a56a-445a-906a-961d3aff9120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['প', '##র', '##ধ', '##া', '##ন', '##ম', '##ন', '##ত', '##র', '##ী', 'শ', '##ে', '##খ', 'হ', '##া', '##স', '##ি', '##ন', '##া', 'ব', '##ল', '##ে', '##ছ', '##ে', '##ন', ',', '‘', 'আ', '##ম', '##া', '##ক', '##ে', 'ব', '##ে', '##শ', '##ি', 'ক', '##থ', '##া', 'ব', '##ল', '##ল', '##ে', 'স', '##ব', 'ব', '##ন', '##ধ', 'ক', '##র', '##ে', 'দ', '##ি', '##য', '##ে', 'ব', '##স', '##ে', 'থ', '##া', '##ক', '##ব', '।', 'ই', '##ল', '##ে', '##ক', '##শ', '##ন', '##ে', '##র', 'প', '##র', '##ে', ',', 'য', '##দ', '##ি', 'আ', '##স', '##ত', '##ে', 'প', '##া', '##র', '##ি', ',', 'আ', '##ব', '##া', '##র', 'ক', '##র', '##ব', '।', 'ত', '##া', '##র', '##প', '##র', 'দ', '##ে', '##খ', '##ি', 'ক', '##ে', 'স', '##া', '##হ', '##স', 'প', '##া', '##য', 'ন', '##ি', '##ত', '##ে', '.', '.', '.', 'ক', '##ষ', '##ম', '##ত', '##া', '।']\n",
      "['প', '##র', '##ত', '##া', '##র', '##ণ', '##া', 'ও', 'জ', '##া', '##ল', '##ি', '##য', '##া', '##ত', '##ি', '##র', 'ম', '##া', '##ম', '##ল', '##া', '##য', 'ক', '##ম', '##ি', '##ল', '##ল', '##া', 'দ', '##ক', '##ষ', '##ি', '##ণ', 'জ', '##ে', '##ল', '##া', 'আ', '##ও', '##য', '##া', '##ম', '##ী', 'ল', '##ী', '##গ', '##ে', '##র', 'স', '##া', '##ং', '##স', '##ক', '##ত', '##ি', '##ক', 'স', '##ম', '##প', '##া', '##দ', '##ক', 'ন', '##ি', '##শ', '##া', '##ত', 'আ', '##হ', '##ম', '##ে', '##দ', 'খ', '##া', '##ন', '##ক', '##ে', 'গ', '##র', '##ে', '##প', '##ত', '##া', '##র', 'ক', '##র', '##ে', '##ছ', '##ে', 'প', '##ল', '##ি', '##শ', '।', 'ব', '##ধ', '##ব', '##া', '##র', 'র', '##া', '##জ', '##ধ', '##া', '##ন', '##ী', '##র', 'ব', '##ন', '##শ', '##র', '##ী', 'এ', '##ল', '##া', '##ক', '##া', '##র', 'এ', '##ক', '##ট', '##ি', 'ব', '##া', '##স', '##া', 'থ', '##ে', '##ক', '##ে', 'ত', '##া', '##ক', '##ে', 'গ', '##র', '##ে', '##প', '##ত', '##া', '##র', 'ক', '##র', '##া', 'হ', '##য', '।']\n",
      "['দ', '##ে', '##শ', '##ে', '[UNK]', 'ম', '##দ', '##র', '##া', '##র', 'র', '##ি', '##জ', '##া', '##র', '##ভ', 'ক', '##ম', '##ছ', '##ে', '##ই', '।', 'গ', '##ত', 'স', '##ে', '##প', '##ট', '##ে', '##ম', '##ব', '##র', 'ম', '##া', '##স', '##ে', '##র', 'প', '##র', '##থ', '##ম', '[UNK]', 'দ', '##ি', '##ন', '##ে', '[UNK]', 'ম', '##দ', '##র', '##া', '##র', 'র', '##ি', '##জ', '##া', '##র', '##ভ', 'ক', '##ম', '##ে', '##ছ', '##ি', '##ল', '[UNK]', 'ক', '##ে', '##া', '##ট', '##ি', '[UNK]', 'ল', '##া', '##খ', 'ম', '##া', '##র', '##ক', '##ি', '##ন', 'ড', '##ল', '##া', '##র']\n"
     ]
    }
   ],
   "source": [
    "for text in sentences:\n",
    "    print(distilbert_tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "defa6a48-2b91-403b-91d9-83fc31cc664c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dad76ee89c14442a3394a3cad80868d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/222 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561fbbfbd9a148f3ac7ba2a520a8f4b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b7741192db42d083ce5b6b70101283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['à¦ªà§įà¦°à¦§à¦¾à¦¨à¦®à¦¨à§įà¦¤à§įà¦°à§Ģ', 'Ġà¦¶à§ĩà¦ĸ', 'Ġà¦¹à¦¾à¦¸à¦¿à¦¨à¦¾', 'Ġà¦¬à¦²à§ĩà¦Ľà§ĩà¦¨', ',', 'ĠâĢĺ', 'à¦Ĩà¦®à¦¾à¦ķà§ĩ', 'Ġà¦¬à§ĩà¦¶à¦¿', 'Ġà¦ķà¦¥à¦¾', 'Ġà¦¬à¦²à¦²à§ĩ', 'Ġà¦¸à¦¬', 'Ġà¦¬à¦¨à§įà¦§', 'Ġà¦ķà¦°à§ĩ', 'Ġà¦¦à¦¿à§Łà§ĩ', 'Ġà¦¬à¦¸à§ĩ', 'Ġà¦¥à¦¾à¦ķ', 'à¦¬', 'à¥¤', 'Ġà¦ĩà¦²à§ĩà¦ķ', 'à¦¶', 'à¦¨à§ĩà¦°', 'Ġà¦ªà¦°à§ĩ', ',', 'Ġà¦¯à¦¦à¦¿', 'Ġà¦Ĩà¦¸à¦¤à§ĩ', 'Ġà¦ªà¦¾à¦°à¦¿', ',', 'Ġà¦Ĩà¦¬à¦¾à¦°', 'Ġà¦ķà¦°à¦¬', 'à¥¤', 'Ġà¦¤à¦¾à¦°à¦ªà¦°', 'Ġà¦¦à§ĩà¦ĸà¦¿', 'Ġà¦ķà§ĩ', 'Ġà¦¸à¦¾à¦¹à¦¸', 'Ġà¦ªà¦¾à§Ł', 'Ġà¦¨à¦¿à¦¤à§ĩ', '...', 'à¦ķà§įà¦·à¦®à¦¤à¦¾', 'à¥¤']\n",
      "['à¦ªà§įà¦°à¦¤', 'à¦¾à¦°à¦£à¦¾', 'Ġà¦ĵ', 'Ġà¦ľà¦¾à¦²', 'à¦¿à¦¯à¦¼à¦¾à¦¤', 'à¦¿à¦°', 'Ġà¦®à¦¾à¦®à¦²à¦¾à¦¯à¦¼', 'Ġà¦ķà§ģà¦®à¦¿à¦²à§įà¦²', 'à¦¾', 'Ġà¦¦à¦ķà§įà¦·à¦¿à¦£', 'Ġà¦ľà§ĩà¦²à¦¾', 'Ġà¦Ĩà¦ĵà§Łà¦¾à¦®à§Ģ', 'Ġà¦²à§Ģà¦Ĺà§ĩà¦°', 'Ġà¦¸à¦¾à¦Ĥà¦¸à§įà¦ķà§ĥà¦¤à¦¿à¦ķ', 'Ġà¦¸à¦®à§įà¦ªà¦¾à¦¦à¦ķ', 'Ġà¦¨à¦¿à¦¶', 'à¦¾à¦¤', 'Ġà¦Ĩà¦¹à¦®à§ĩà¦¦', 'Ġà¦ĸà¦¾à¦¨', 'à¦ķà§ĩ', 'Ġà¦Ĺà§įà¦°à§ĩà¦ªà§įà¦¤à¦¾à¦°', 'Ġà¦ķà¦°à§ĩà¦Ľà§ĩ', 'Ġà¦ªà§ģà¦²à¦¿à¦¶', 'à¥¤', 'Ġà¦¬à§ģà¦§à¦¬à¦¾à¦°', 'Ġà¦°à¦¾à¦ľà¦§à¦¾à¦¨à§Ģà¦°', 'Ġà¦¬à¦¨', 'à¦¶à§įà¦°à§Ģ', 'Ġà¦ıà¦²à¦¾à¦ķà¦¾à¦°', 'Ġà¦ıà¦ķà¦Łà¦¿', 'Ġà¦¬à¦¾à¦¸à¦¾', 'Ġà¦¥à§ĩà¦ķà§ĩ', 'Ġà¦¤à¦¾à¦ģà¦ķà§ĩ', 'Ġà¦Ĺà§įà¦°à§ĩà¦ªà§įà¦¤à¦¾à¦°', 'Ġà¦ķà¦°à¦¾', 'Ġà¦¹à¦¯à¦¼', 'à¥¤']\n",
      "['à¦¦à§ĩà¦¶à§ĩ', 'Ġà¦¬à§Ī', 'à¦¦à§ĩà¦¶', 'à¦¿à¦ķ', 'Ġà¦®à§ģà¦¦à§įà¦°', 'à¦¾à¦°', 'Ġà¦°à¦¿à¦ľ', 'à¦¾à¦°à§įà¦Ń', 'Ġà¦ķà¦®', 'à¦Ľ', 'à§ĩà¦ĩ', 'à¥¤', 'Ġà¦Ĺà¦¤', 'Ġà¦¸à§ĩà¦ªà§įà¦Łà§ĩà¦®à§įà¦¬à¦°', 'Ġà¦®à¦¾à¦¸à§ĩà¦°', 'Ġà¦ªà§įà¦°à¦¥à¦®', 'Ġà§¨à§¬', 'Ġà¦¦à¦¿à¦¨à§ĩ', 'Ġà¦¬à§Ī', 'à¦¦à§ĩà¦¶', 'à¦¿à¦ķ', 'Ġà¦®à§ģà¦¦à§įà¦°', 'à¦¾à¦°', 'Ġà¦°à¦¿à¦ľ', 'à¦¾à¦°à§įà¦Ń', 'Ġà¦ķà¦®', 'à§ĩà¦Ľà¦¿à¦²', 'Ġà§§à§¯à§', '§', 'Ġà¦ķà§ĭà¦Łà¦¿', 'Ġà§ªà§®', 'Ġà¦²à¦¾à¦ĸ', 'Ġà¦®à¦¾à¦°à§įà¦ķà¦¿à¦¨', 'Ġà¦¡à¦²à¦¾à¦°']\n"
     ]
    }
   ],
   "source": [
    "bloom_tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-560m\")\n",
    "for text in sentences:\n",
    "    print(bloom_tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "473604dc-aac3-45c0-94b1-ce6436e664de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-07 10:30:20.488580: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-07 10:30:22.131053: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b57b91d841bc4a5ea34a4d4c5de0a23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a8b767b5e2438392321133bdf2bf59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452c5818355f4b4db8e7217a23429be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8bed12d-4111-434b-9029-f819b927a988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['à¦', 'ª', 'à', '§', 'į', 'à¦', '°', 'à¦', '§', 'à¦', '¾', 'à¦', '¨', 'à¦', '®', 'à¦', '¨', 'à', '§', 'į', 'à¦', '¤', 'à', '§', 'į', 'à¦', '°', 'à', '§', 'Ģ', 'Ġ', 'à¦', '¶', 'à', '§', 'ĩ', 'à¦', 'ĸ', 'Ġ', 'à¦', '¹', 'à¦', '¾', 'à¦', '¸', 'à¦', '¿', 'à¦', '¨', 'à¦', '¾', 'Ġ', 'à¦', '¬', 'à¦', '²', 'à', '§', 'ĩ', 'à¦', 'Ľ', 'à', '§', 'ĩ', 'à¦', '¨', ',', 'ĠâĢ', 'ĺ', 'à¦', 'Ĩ', 'à¦', '®', 'à¦', '¾', 'à¦', 'ķ', 'à', '§', 'ĩ', 'Ġ', 'à¦', '¬', 'à', '§', 'ĩ', 'à¦', '¶', 'à¦', '¿', 'Ġ', 'à¦', 'ķ', 'à¦', '¥', 'à¦', '¾', 'Ġ', 'à¦', '¬', 'à¦', '²', 'à¦', '²', 'à', '§', 'ĩ', 'Ġ', 'à¦', '¸', 'à¦', '¬', 'Ġ', 'à¦', '¬', 'à¦', '¨', 'à', '§', 'į', 'à¦', '§', 'Ġ', 'à¦', 'ķ', 'à¦', '°', 'à', '§', 'ĩ', 'Ġ', 'à¦', '¦', 'à¦', '¿', 'à', '§', 'Ł', 'à', '§', 'ĩ', 'Ġ', 'à¦', '¬', 'à¦', '¸', 'à', '§', 'ĩ', 'Ġ', 'à¦', '¥', 'à¦', '¾', 'à¦', 'ķ', 'à¦', '¬', 'à¥', '¤', 'Ġ', 'à¦', 'ĩ', 'à¦', '²', 'à', '§', 'ĩ', 'à¦', 'ķ', 'à¦', '¶', 'à¦', '¨', 'à', '§', 'ĩ', 'à¦', '°', 'Ġ', 'à¦', 'ª', 'à¦', '°', 'à', '§', 'ĩ', ',', 'Ġ', 'à¦', '¯', 'à¦', '¦', 'à¦', '¿', 'Ġ', 'à¦', 'Ĩ', 'à¦', '¸', 'à¦', '¤', 'à', '§', 'ĩ', 'Ġ', 'à¦', 'ª', 'à¦', '¾', 'à¦', '°', 'à¦', '¿', ',', 'Ġ', 'à¦', 'Ĩ', 'à¦', '¬', 'à¦', '¾', 'à¦', '°', 'Ġ', 'à¦', 'ķ', 'à¦', '°', 'à¦', '¬', 'à¥', '¤', 'Ġ', 'à¦', '¤', 'à¦', '¾', 'à¦', '°', 'à¦', 'ª', 'à¦', '°', 'Ġ', 'à¦', '¦', 'à', '§', 'ĩ', 'à¦', 'ĸ', 'à¦', '¿', 'Ġ', 'à¦', 'ķ', 'à', '§', 'ĩ', 'Ġ', 'à¦', '¸', 'à¦', '¾', 'à¦', '¹', 'à¦', '¸', 'Ġ', 'à¦', 'ª', 'à¦', '¾', 'à', '§', 'Ł', 'Ġ', 'à¦', '¨', 'à¦', '¿', 'à¦', '¤', 'à', '§', 'ĩ', '...', 'à¦', 'ķ', 'à', '§', 'į', 'à¦', '·', 'à¦', '®', 'à¦', '¤', 'à¦', '¾', 'à¥', '¤']\n",
      "['à¦', 'ª', 'à', '§', 'į', 'à¦', '°', 'à¦', '¤', 'à¦', '¾', 'à¦', '°', 'à¦', '£', 'à¦', '¾', 'Ġ', 'à¦', 'ĵ', 'Ġ', 'à¦', 'ľ', 'à¦', '¾', 'à¦', '²', 'à¦', '¿', 'à¦', '¯', 'à¦', '¼', 'à¦', '¾', 'à¦', '¤', 'à¦', '¿', 'à¦', '°', 'Ġ', 'à¦', '®', 'à¦', '¾', 'à¦', '®', 'à¦', '²', 'à¦', '¾', 'à¦', '¯', 'à¦', '¼', 'Ġ', 'à¦', 'ķ', 'à', '§', 'ģ', 'à¦', '®', 'à¦', '¿', 'à¦', '²', 'à', '§', 'į', 'à¦', '²', 'à¦', '¾', 'Ġ', 'à¦', '¦', 'à¦', 'ķ', 'à', '§', 'į', 'à¦', '·', 'à¦', '¿', 'à¦', '£', 'Ġ', 'à¦', 'ľ', 'à', '§', 'ĩ', 'à¦', '²', 'à¦', '¾', 'Ġ', 'à¦', 'Ĩ', 'à¦', 'ĵ', 'à', '§', 'Ł', 'à¦', '¾', 'à¦', '®', 'à', '§', 'Ģ', 'Ġ', 'à¦', '²', 'à', '§', 'Ģ', 'à¦', 'Ĺ', 'à', '§', 'ĩ', 'à¦', '°', 'Ġ', 'à¦', '¸', 'à¦', '¾', 'à¦', 'Ĥ', 'à¦', '¸', 'à', '§', 'į', 'à¦', 'ķ', 'à', '§', 'ĥ', 'à¦', '¤', 'à¦', '¿', 'à¦', 'ķ', 'Ġ', 'à¦', '¸', 'à¦', '®', 'à', '§', 'į', 'à¦', 'ª', 'à¦', '¾', 'à¦', '¦', 'à¦', 'ķ', 'Ġ', 'à¦', '¨', 'à¦', '¿', 'à¦', '¶', 'à¦', '¾', 'à¦', '¤', 'Ġ', 'à¦', 'Ĩ', 'à¦', '¹', 'à¦', '®', 'à', '§', 'ĩ', 'à¦', '¦', 'Ġ', 'à¦', 'ĸ', 'à¦', '¾', 'à¦', '¨', 'à¦', 'ķ', 'à', '§', 'ĩ', 'Ġ', 'à¦', 'Ĺ', 'à', '§', 'į', 'à¦', '°', 'à', '§', 'ĩ', 'à¦', 'ª', 'à', '§', 'į', 'à¦', '¤', 'à¦', '¾', 'à¦', '°', 'Ġ', 'à¦', 'ķ', 'à¦', '°', 'à', '§', 'ĩ', 'à¦', 'Ľ', 'à', '§', 'ĩ', 'Ġ', 'à¦', 'ª', 'à', '§', 'ģ', 'à¦', '²', 'à¦', '¿', 'à¦', '¶', 'à¥', '¤', 'Ġ', 'à¦', '¬', 'à', '§', 'ģ', 'à¦', '§', 'à¦', '¬', 'à¦', '¾', 'à¦', '°', 'Ġ', 'à¦', '°', 'à¦', '¾', 'à¦', 'ľ', 'à¦', '§', 'à¦', '¾', 'à¦', '¨', 'à', '§', 'Ģ', 'à¦', '°', 'Ġ', 'à¦', '¬', 'à¦', '¨', 'à¦', '¶', 'à', '§', 'į', 'à¦', '°', 'à', '§', 'Ģ', 'Ġ', 'à¦', 'ı', 'à¦', '²', 'à¦', '¾', 'à¦', 'ķ', 'à¦', '¾', 'à¦', '°', 'Ġ', 'à¦', 'ı', 'à¦', 'ķ', 'à¦', 'Ł', 'à¦', '¿', 'Ġ', 'à¦', '¬', 'à¦', '¾', 'à¦', '¸', 'à¦', '¾', 'Ġ', 'à¦', '¥', 'à', '§', 'ĩ', 'à¦', 'ķ', 'à', '§', 'ĩ', 'Ġ', 'à¦', '¤', 'à¦', '¾', 'à¦', 'ģ', 'à¦', 'ķ', 'à', '§', 'ĩ', 'Ġ', 'à¦', 'Ĺ', 'à', '§', 'į', 'à¦', '°', 'à', '§', 'ĩ', 'à¦', 'ª', 'à', '§', 'į', 'à¦', '¤', 'à¦', '¾', 'à¦', '°', 'Ġ', 'à¦', 'ķ', 'à¦', '°', 'à¦', '¾', 'Ġ', 'à¦', '¹', 'à¦', '¯', 'à¦', '¼', 'à¥', '¤']\n",
      "['à¦', '¦', 'à', '§', 'ĩ', 'à¦', '¶', 'à', '§', 'ĩ', 'Ġ', 'à¦', '¬', 'à', '§', 'Ī', 'à¦', '¦', 'à', '§', 'ĩ', 'à¦', '¶', 'à¦', '¿', 'à¦', 'ķ', 'Ġ', 'à¦', '®', 'à', '§', 'ģ', 'à¦', '¦', 'à', '§', 'į', 'à¦', '°', 'à¦', '¾', 'à¦', '°', 'Ġ', 'à¦', '°', 'à¦', '¿', 'à¦', 'ľ', 'à¦', '¾', 'à¦', '°', 'à', '§', 'į', 'à¦', 'Ń', 'Ġ', 'à¦', 'ķ', 'à¦', '®', 'à¦', 'Ľ', 'à', '§', 'ĩ', 'à¦', 'ĩ', 'à¥', '¤', 'Ġ', 'à¦', 'Ĺ', 'à¦', '¤', 'Ġ', 'à¦', '¸', 'à', '§', 'ĩ', 'à¦', 'ª', 'à', '§', 'į', 'à¦', 'Ł', 'à', '§', 'ĩ', 'à¦', '®', 'à', '§', 'į', 'à¦', '¬', 'à¦', '°', 'Ġ', 'à¦', '®', 'à¦', '¾', 'à¦', '¸', 'à', '§', 'ĩ', 'à¦', '°', 'Ġ', 'à¦', 'ª', 'à', '§', 'į', 'à¦', '°', 'à¦', '¥', 'à¦', '®', 'Ġ', 'à', '§', '¨', 'à', '§', '¬', 'Ġ', 'à¦', '¦', 'à¦', '¿', 'à¦', '¨', 'à', '§', 'ĩ', 'Ġ', 'à¦', '¬', 'à', '§', 'Ī', 'à¦', '¦', 'à', '§', 'ĩ', 'à¦', '¶', 'à¦', '¿', 'à¦', 'ķ', 'Ġ', 'à¦', '®', 'à', '§', 'ģ', 'à¦', '¦', 'à', '§', 'į', 'à¦', '°', 'à¦', '¾', 'à¦', '°', 'Ġ', 'à¦', '°', 'à¦', '¿', 'à¦', 'ľ', 'à¦', '¾', 'à¦', '°', 'à', '§', 'į', 'à¦', 'Ń', 'Ġ', 'à¦', 'ķ', 'à¦', '®', 'à', '§', 'ĩ', 'à¦', 'Ľ', 'à¦', '¿', 'à¦', '²', 'Ġ', 'à', '§', '§', 'à', '§', '¯', 'à', '§', '§', 'Ġ', 'à¦', 'ķ', 'à', '§', 'ĭ', 'à¦', 'Ł', 'à¦', '¿', 'Ġ', 'à', '§', 'ª', 'à', '§', '®', 'Ġ', 'à¦', '²', 'à¦', '¾', 'à¦', 'ĸ', 'Ġ', 'à¦', '®', 'à¦', '¾', 'à¦', '°', 'à', '§', 'į', 'à¦', 'ķ', 'à¦', '¿', 'à¦', '¨', 'Ġ', 'à¦', '¡', 'à¦', '²', 'à¦', '¾', 'à¦', '°']\n"
     ]
    }
   ],
   "source": [
    "for text in sentences:\n",
    "    print(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ab37362-c226-48de-9b14-e1edd7b225b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nLlamaTokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LlamaForCausalLM, LlamaTokenizer\n\u001b[0;32m----> 3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/output/path\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py:1124\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[0;32m-> 1124\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py:1112\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1110\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[0;32m-> 1112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
      "\u001b[0;31mImportError\u001b[0m: \nLlamaTokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"/output/path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ed1b39-4134-4d0f-a89c-f604fa609284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
